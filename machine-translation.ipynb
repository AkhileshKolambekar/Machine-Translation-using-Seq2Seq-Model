{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":428282,"sourceType":"datasetVersion","datasetId":192461}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn.utils.rnn import pad_sequence\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\nimport random\n\nimport spacy\nfrom transformers import AutoTokenizer\nimport string\nimport re\n\nimport itertools\n\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-09-15T17:34:01.075575Z","iopub.execute_input":"2024-09-15T17:34:01.076034Z","iopub.status.idle":"2024-09-15T17:34:08.866823Z","shell.execute_reply.started":"2024-09-15T17:34:01.075993Z","shell.execute_reply":"2024-09-15T17:34:08.865967Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/english-to-hindi/hin.txt',sep = '\\t',names = ['english_sentence','hindi_sentence'])\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-15T17:34:08.868419Z","iopub.execute_input":"2024-09-15T17:34:08.868933Z","iopub.status.idle":"2024-09-15T17:34:08.914780Z","shell.execute_reply.started":"2024-09-15T17:34:08.868898Z","shell.execute_reply":"2024-09-15T17:34:08.913805Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"  english_sentence hindi_sentence\n0             Wow!           वाह!\n1            Help!          बचाओ!\n2            Jump.          उछलो.\n3            Jump.          कूदो.\n4            Jump.         छलांग.","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>english_sentence</th>\n      <th>hindi_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Wow!</td>\n      <td>वाह!</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Help!</td>\n      <td>बचाओ!</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Jump.</td>\n      <td>उछलो.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Jump.</td>\n      <td>कूदो.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Jump.</td>\n      <td>छलांग.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#torch.backends.cudnn.benchmark = True\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-09-15T17:34:08.915987Z","iopub.execute_input":"2024-09-15T17:34:08.916289Z","iopub.status.idle":"2024-09-15T17:34:08.920590Z","shell.execute_reply.started":"2024-09-15T17:34:08.916258Z","shell.execute_reply":"2024-09-15T17:34:08.919696Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"eng_tokenizer = spacy.load(\"en_core_web_sm\")\nhin_tokenizer = AutoTokenizer.from_pretrained('raunaqjabbal/hindi-tokenizer')","metadata":{"execution":{"iopub.status.busy":"2024-09-15T17:34:08.922394Z","iopub.execute_input":"2024-09-15T17:34:08.922673Z","iopub.status.idle":"2024-09-15T17:34:35.466088Z","shell.execute_reply.started":"2024-09-15T17:34:08.922643Z","shell.execute_reply":"2024-09-15T17:34:35.465086Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/11.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5c4fa7d10b2484c9e34024d51e5d1c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/607k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89654c98b8aa4091861ca260acd0ccd8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/12.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ced9e9f526b841f1a4d02944b2128700"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/1.97M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7709cd3dbd3f426690548c6a17b47438"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66c93131bb19447a85851d0a37d7e7e7"}},"metadata":{}}]},{"cell_type":"code","source":"class Vocabulary:\n    \n    def __init__(self,freq_threshold):\n        self.freq_threshold = freq_threshold\n        \n        self.en_stoi = {'<pad>':0,'<sos>':1,'<eos>':2,'<unk>':3}\n        self.en_itos = {0:'<pad>',1:'<sos>',2:'<eos>',3:'<unk>'}\n        \n        self.hi_stoi = {'<pad>':0,'<sos>':1,'<eos>':2,'<unk>':3}\n        self.hi_itos = {0:'<pad>',1:'<sos>',2:'<eos>',3:'<unk>'}\n        \n    def __len__(self):\n        return len(self.en_stoi)\n    \n    def tokenize_eng(self, en_text):\n        return [token.text.lower() for token in eng_tokenizer.tokenizer(en_text)]\n    \n    def tokenize_hin(self,hi_text):\n        return hin_tokenizer.tokenize(hi_text)\n    \n    def build_vocabulary(self, sentences, lang):\n        frequencies = {}\n        idx = 4\n        \n        if lang == 'english':\n            for sentence in sentences:\n                for word in self.tokenize_eng(sentence):\n                    if word not in frequencies:\n                        frequencies[word] = 1\n                    else:\n                        frequencies[word] += 1\n\n                    if frequencies[word] == self.freq_threshold and len(word)>1 and word.isalpha():\n                        self.en_stoi[word] = idx\n                        self.en_itos[idx] = word\n                        idx += 1\n        else:\n            for sentence in sentences:\n                for word in self.tokenize_hin(sentence):\n                    if word not in frequencies:\n                        frequencies[word] = 1\n                    else:\n                        frequencies[word] += 1\n\n                    if frequencies[word] == self.freq_threshold and len(word)>1:\n                        self.hi_stoi[word] = idx\n                        self.hi_itos[idx] = word\n                        idx += 1\n    \n    def english_vector(self, text):\n        tokenized_text = self.tokenize_eng(text)\n        \n        numerical_sentence = [self.en_stoi['<sos>']]\n        numerical_sentence += [self.en_stoi[word] if word in self.en_stoi else self.en_stoi['<unk>'] for word in tokenized_text]\n        numerical_sentence.append(self.en_stoi['<eos>'])\n        \n        return numerical_sentence\n    \n    def hindi_vector(self, text):\n        tokenized_text = self.tokenize_hin(text)\n        \n        numerical_sentence = [self.hi_stoi['<sos>']]\n        numerical_sentence += [self.hi_stoi[word] if word in self.hi_stoi else self.hi_stoi['<unk>'] for word in tokenized_text]\n        numerical_sentence.append(self.hi_stoi['<eos>'])\n        \n        return numerical_sentence\n            ","metadata":{"execution":{"iopub.status.busy":"2024-09-15T17:34:35.467899Z","iopub.execute_input":"2024-09-15T17:34:35.468208Z","iopub.status.idle":"2024-09-15T17:34:35.484210Z","shell.execute_reply.started":"2024-09-15T17:34:35.468175Z","shell.execute_reply":"2024-09-15T17:34:35.483233Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class TextData(Dataset):\n    \n    def __init__(self, freq_threshold, max_length):\n                \n        self.df = pd.read_csv('/kaggle/input/english-to-hindi/hin.txt',sep = '\\t',names = ['english_sentence','hindi_sentence'])\n        self.df.dropna(inplace = True)\n        \n        self.vocab = Vocabulary(freq_threshold)\n        self.vocab.build_vocabulary(self.df['english_sentence'],'english')\n        self.vocab.build_vocabulary(self.df['hindi_sentence'],'hindi')\n        \n        print('English Vocabulary Size - ',len(self.vocab.en_stoi))\n        print('Hindi Vocabulary Size - ',len(self.vocab.hi_stoi))\n        \n        self.vocab.en_stoi = dict(itertools.islice(self.vocab.en_stoi.items(), max_length))\n        self.vocab.en_itos = dict(itertools.islice(self.vocab.en_itos.items(), max_length))\n        \n        self.vocab.hi_stoi = dict(itertools.islice(self.vocab.hi_stoi.items(), max_length))\n        self.vocab.hi_itos = dict(itertools.islice(self.vocab.hi_itos.items(), max_length))\n        \n        self.pad_idx = self.vocab.en_stoi['<pad>']\n    \n        self.english_sentences = self.df['english_sentence'].to_list()\n        self.hindi_sentences = self.df['hindi_sentence'].to_list()\n    \n    def __len__(self):\n        return self.df.shape[0]\n\n    def __getitem__(self, index):\n        eng_tokenized = torch.tensor(self.vocab.english_vector(self.english_sentences[index]))\n        hin_tokenized = torch.tensor(self.vocab.hindi_vector(self.hindi_sentences[index]))\n        return eng_tokenized, hin_tokenized\n\nclass MyCollate:\n    \n    def __init__(self,pad_idx):\n        self.pad_idx = pad_idx\n    \n    def __call__(self, batch):\n        eng_sentences = [item[0] for item in batch]\n        hin_sentences = [item[1] for item in batch]\n        \n        eng_sentences = pad_sequence(eng_sentences, batch_first = False, padding_value = self.pad_idx)\n        hin_sentences = pad_sequence(hin_sentences, batch_first = False, padding_value = self.pad_idx)\n        \n        return eng_sentences, hin_sentences","metadata":{"execution":{"iopub.status.busy":"2024-09-15T17:34:35.485623Z","iopub.execute_input":"2024-09-15T17:34:35.486064Z","iopub.status.idle":"2024-09-15T17:34:35.499271Z","shell.execute_reply.started":"2024-09-15T17:34:35.486020Z","shell.execute_reply":"2024-09-15T17:34:35.498405Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    \n    def __init__(self, input_size, embed_size, hidden_size, num_layers):\n        super(Encoder, self).__init__()\n        \n        self.embed = nn.Embedding(input_size, embed_size)\n        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers)\n        self.dropout = nn.Dropout(0.5)\n    \n    def forward(self, x):\n        # shape of x: (seq_len, N) \n        # where N is batch size\n        # seq_len is the number of words being sent\n        embeddings = self.embed(x) \n        \n        # embeddings shape: (seq_len, N, embed_size)\n        outputs, (hidden,cell) = self.lstm(embeddings)\n        \n        # outputs shape: (seq_len ,N, hidden_size)\n        return hidden, cell\n\nclass Decoder(nn.Module):\n    \n    def __init__(self, input_size, embed_size, hidden_size, output_size,num_layers):\n        super(Decoder, self).__init__()\n        \n        self.embed = nn.Embedding(input_size, embed_size)\n        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers)\n        self.fc = nn.Linear(hidden_size, output_size)\n        self.dropout = nn.Dropout(0.5)\n    \n    def forward(self, x, hidden, cell):\n        # Here x is of the shape (N), and we want to convert it to (1,N)\n        # 1 here is seq_len, since we are passing only one word\n        x = x.unsqueeze(0)\n        \n        # x shape: (1,N)\n        embeddings = self.embed(x)\n        \n        # embeddings shape: (1,N,embed_size)\n        outputs, (hidden, cell) = self.lstm(embeddings, (hidden, cell))\n        \n        # outputs shape: (1,N, hidden_size)\n        predictions = self.fc(outputs)\n        \n        # predictions,shape: (1,N,output_size)\n        # loss function needs shape (N, output_size) so we're\n        # just gonna remove the first dim\n        predictions = predictions.squeeze(0)\n        \n        return predictions, hidden, cell\n\nclass Translator(nn.Module):\n    \n    def __init__(self, encoder, decoder):\n        super(Translator, self).__init__()\n        \n        self.encoder = encoder\n        self.decoder = decoder\n    \n    def forward(self, source, target, teacher_force_ratio = 0.5):\n        batch_size = source.shape[1] # shape: (seq_len, N)\n        target_len = target.shape[0]\n        target_vocab_size = len(dataset.vocab.en_stoi)\n        \n        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n        \n        hidden,cell = self.encoder(source)\n        \n        x = target[0] # Get <sos>\n        \n        for t in range(1,target_len):\n            output, hidden, cell = self.decoder(x, hidden, cell)\n            \n            outputs[t] = output\n            \n            best_guess = torch.argmax(output)\n            #print(best_guess)\n            \n            x = target[t]\n        \n        return outputs","metadata":{"execution":{"iopub.status.busy":"2024-09-15T17:34:35.501859Z","iopub.execute_input":"2024-09-15T17:34:35.502548Z","iopub.status.idle":"2024-09-15T17:34:35.516881Z","shell.execute_reply.started":"2024-09-15T17:34:35.502504Z","shell.execute_reply":"2024-09-15T17:34:35.516005Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"dataset = TextData(10,260)\n\nloader = DataLoader(\n    dataset = dataset,\n    batch_size = 32,\n    shuffle = True,\n    collate_fn = MyCollate(pad_idx = 0),\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T17:50:06.329930Z","iopub.execute_input":"2024-09-15T17:50:06.330661Z","iopub.status.idle":"2024-09-15T17:50:06.678687Z","shell.execute_reply.started":"2024-09-15T17:50:06.330621Z","shell.execute_reply":"2024-09-15T17:50:06.677708Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"English Vocabulary Size -  265\nHindi Vocabulary Size -  368\n","output_type":"stream"}]},{"cell_type":"code","source":"num_epochs = 100\nlearning_rate = 0.001\nbatch_size = 32\n\ninput_size_encoder = len(dataset.vocab.en_stoi)\ninput_size_decoder = len(dataset.vocab.hi_stoi)\n\nembed_size = 256\n\noutput_size = len(dataset.vocab.en_stoi)\n\nhidden_size = 256\nnum_layers = 2","metadata":{"execution":{"iopub.status.busy":"2024-09-15T17:50:40.354821Z","iopub.execute_input":"2024-09-15T17:50:40.355199Z","iopub.status.idle":"2024-09-15T17:50:40.360887Z","shell.execute_reply.started":"2024-09-15T17:50:40.355165Z","shell.execute_reply":"2024-09-15T17:50:40.359900Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"encoder = Encoder(input_size_encoder, embed_size, hidden_size, num_layers).to(device)\ndecoder = Decoder(input_size_decoder, embed_size, hidden_size, output_size, num_layers).to(device)\ntranslator = Translator(encoder,decoder).to(device)\n\noptimizer = optim.Adam(translator.parameters(), lr = learning_rate)\ncriterion = nn.CrossEntropyLoss(ignore_index = 0)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T17:50:40.636646Z","iopub.execute_input":"2024-09-15T17:50:40.637540Z","iopub.status.idle":"2024-09-15T17:50:40.670255Z","shell.execute_reply.started":"2024-09-15T17:50:40.637497Z","shell.execute_reply":"2024-09-15T17:50:40.669451Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    \n    #translator.train()\n    \n    for batch_idx, (eng_sentences, hin_sentences) in tqdm(enumerate(loader),total = len(loader), leave = False):\n        eng_sent_list = eng_sentences.to(device)\n        hin_sent_list = hin_sentences.to(device)\n        \n        output = translator(eng_sent_list, hin_sent_list)\n        \n        output = output[1:].reshape(-1, output.shape[2])\n        hin_sent_list = hin_sent_list[1:].reshape(-1)\n        \n        loss = criterion(output,hin_sent_list)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(translator.parameters(), max_norm=1)\n        optimizer.step()\n    \n    print(f'Epoch - {epoch+1}/{num_epochs}, Loss - {loss}')","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-09-15T17:50:40.830429Z","iopub.execute_input":"2024-09-15T17:50:40.830862Z","iopub.status.idle":"2024-09-15T17:56:43.223461Z","shell.execute_reply.started":"2024-09-15T17:50:40.830821Z","shell.execute_reply":"2024-09-15T17:56:43.222494Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 1/100, Loss - 3.4572300910949707\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 2/100, Loss - 2.9711129665374756\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 3/100, Loss - 2.851594924926758\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 4/100, Loss - 2.620299816131592\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 5/100, Loss - 2.4703550338745117\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 6/100, Loss - 2.3842270374298096\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 7/100, Loss - 1.9746005535125732\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 8/100, Loss - 2.0658698081970215\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 9/100, Loss - 2.2504942417144775\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 10/100, Loss - 2.1644887924194336\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 11/100, Loss - 1.7776215076446533\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 12/100, Loss - 1.7767635583877563\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 13/100, Loss - 1.6396008729934692\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 14/100, Loss - 1.4502800703048706\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 15/100, Loss - 1.4784351587295532\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 16/100, Loss - 1.298967957496643\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 17/100, Loss - 1.088638424873352\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 18/100, Loss - 0.8755085468292236\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 19/100, Loss - 0.8410502672195435\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 20/100, Loss - 0.7431150078773499\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 21/100, Loss - 0.8212277293205261\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 22/100, Loss - 0.5538183450698853\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 23/100, Loss - 0.6262295246124268\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 24/100, Loss - 0.5811991095542908\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 25/100, Loss - 0.476529061794281\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 26/100, Loss - 0.38100725412368774\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 27/100, Loss - 0.3897639214992523\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 28/100, Loss - 0.22639711201190948\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 29/100, Loss - 0.3453122079372406\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 30/100, Loss - 0.1916462928056717\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 31/100, Loss - 0.27130287885665894\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 32/100, Loss - 0.16365934908390045\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 33/100, Loss - 0.16445380449295044\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 34/100, Loss - 0.09851576387882233\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 35/100, Loss - 0.22310347855091095\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 36/100, Loss - 0.07519522309303284\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 37/100, Loss - 0.2056819051504135\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 38/100, Loss - 0.07744888216257095\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 39/100, Loss - 0.085706427693367\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 40/100, Loss - 0.1260933130979538\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 41/100, Loss - 0.06894758343696594\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 42/100, Loss - 0.08086400479078293\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 43/100, Loss - 0.11735855787992477\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 44/100, Loss - 0.09868873655796051\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 45/100, Loss - 0.097244493663311\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 46/100, Loss - 0.061692483723163605\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 47/100, Loss - 0.10545367002487183\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 48/100, Loss - 0.039516422897577286\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 49/100, Loss - 0.043350785970687866\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 50/100, Loss - 0.0967550277709961\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 51/100, Loss - 0.10996715724468231\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 52/100, Loss - 0.10208574682474136\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 53/100, Loss - 0.36227813363075256\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 54/100, Loss - 0.117117740213871\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 55/100, Loss - 0.03944908455014229\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 56/100, Loss - 0.06149817258119583\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 57/100, Loss - 0.06731389462947845\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 58/100, Loss - 0.030277714133262634\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 59/100, Loss - 0.045321930199861526\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 60/100, Loss - 0.07336197793483734\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 61/100, Loss - 0.01572844572365284\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 62/100, Loss - 0.02019030787050724\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 63/100, Loss - 0.07800281047821045\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 64/100, Loss - 0.05966208875179291\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 65/100, Loss - 0.04261879622936249\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 66/100, Loss - 0.019346412271261215\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 67/100, Loss - 0.08556432276964188\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 68/100, Loss - 0.027949891984462738\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 69/100, Loss - 0.051201727241277695\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 70/100, Loss - 0.03815704956650734\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 71/100, Loss - 0.12321819365024567\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 72/100, Loss - 0.05466196686029434\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 73/100, Loss - 0.12369703501462936\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 74/100, Loss - 0.09495975077152252\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 75/100, Loss - 0.04688311740756035\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 76/100, Loss - 0.21363894641399384\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 77/100, Loss - 0.20163948833942413\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 78/100, Loss - 0.14350302517414093\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 79/100, Loss - 0.10396073013544083\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 80/100, Loss - 0.09787888824939728\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 81/100, Loss - 0.03448847681283951\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 82/100, Loss - 0.0573328360915184\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 83/100, Loss - 0.04282107949256897\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 84/100, Loss - 0.04037195444107056\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 85/100, Loss - 0.005147258285433054\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 86/100, Loss - 0.03913351893424988\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 87/100, Loss - 0.04192572087049484\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 88/100, Loss - 0.0031819725409150124\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 89/100, Loss - 0.004113370552659035\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 90/100, Loss - 0.08737750351428986\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 91/100, Loss - 0.05949858948588371\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 92/100, Loss - 0.06084074079990387\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 93/100, Loss - 0.039124105125665665\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 94/100, Loss - 0.039958395063877106\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 95/100, Loss - 0.050274789333343506\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 96/100, Loss - 0.031248953193426132\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 97/100, Loss - 0.04022153466939926\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 98/100, Loss - 0.04340507835149765\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"Epoch - 99/100, Loss - 0.02403227798640728\n","output_type":"stream"},{"name":"stderr","text":"                                               ","output_type":"stream"},{"name":"stdout","text":"Epoch - 100/100, Loss - 0.05798852816224098\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}]},{"cell_type":"code","source":"eng_sent = \"What are you doing?\"\n\nsentence_tensor = torch.tensor(dataset.vocab.english_vector(eng_sent)).unsqueeze(1).to(device)\n\nwith torch.no_grad():\n    hidden, cell = translator.encoder(sentence_tensor)\n\n\noutputs = [dataset.vocab.hi_stoi['<sos>']]\nfor _ in range(100):\n    previous_word = torch.tensor([outputs[-1]]).to(device)\n    \n    with torch.no_grad():\n        output, hidden, cell = translator.decoder(previous_word, hidden, cell)\n        best_guess = torch.argmax(output).item()\n    \n    outputs.append(best_guess)\n    \n    if output.argmax(1).item() == dataset.vocab.hi_stoi[\"<eos>\"]:\n            break\n\ntranslated_sentence = [dataset.vocab.hi_itos[idx] for idx in outputs]\n\nprint(translated_sentence)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T17:56:43.225349Z","iopub.execute_input":"2024-09-15T17:56:43.225979Z","iopub.status.idle":"2024-09-15T17:56:43.239385Z","shell.execute_reply.started":"2024-09-15T17:56:43.225931Z","shell.execute_reply":"2024-09-15T17:56:43.238198Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"['<sos>', 'तुम', 'क्या', 'कर', 'रहे', '<unk>', '<eos>']\n","output_type":"stream"}]}]}